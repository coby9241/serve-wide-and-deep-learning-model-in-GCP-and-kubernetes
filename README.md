# Serving a Wide & Deep Learning model in Google Cloud Platform and Kubernetes

Credits and Useful Links (I'm spamming abit but that's how many links I referenced):
1. Vitaly Bezgachev's awesome posts, [Part 1](https://towardsdatascience.com/how-to-deploy-machine-learning-models-with-tensorflow-part-1-make-your-model-ready-for-serving-776a14ec3198), [Part 2](https://towardsdatascience.com/how-to-deploy-machine-learning-models-with-tensorflow-part-2-containerize-it-db0ad7ca35a7) and [Part 3](https://towardsdatascience.com/how-to-deploy-machine-learning-models-with-tensorflow-part-3-into-the-cloud-7115ff774bb6). He used Azure but I had some issues with Azure cli so I used GCP instead.
2. [Tensorflow's Inception Serving guide](https://www.tensorflow.org/serving/serving_inception)
3. Yufengg's [widendeep repo](https://github.com/yufengg/widendeep) which I got much of the wide and deep code from
4. Tensorflow's [Wide and Deep Tutorial](https://www.tensorflow.org/tutorials/wide_and_deep)
5. Weimin Wang's [blog post](https://weiminwang.blog/2017/09/12/introductory-guide-to-tensorflow-serving/) for Tensorflow Serving
6. Siraj's [repo for deploying Tensorflow to production](https://github.com/llSourcell/How-to-Deploy-a-Tensorflow-Model-in-Production)
7. https://www.tensorflow.org/versions/r1.2/programmers_guide/saved_model_cli
8. https://stackoverflow.com/questions/44125403/how-to-access-tensor-content-values-in-tensorproto-in-tensorflow
